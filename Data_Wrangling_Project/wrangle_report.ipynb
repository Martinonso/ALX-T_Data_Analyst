{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUCTION:\n",
    "\n",
    "The dataset that we will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter \n",
    "user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's \n",
    "dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. \n",
    "The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \n",
    "\"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international \n",
    "media coverage.\n",
    "\n",
    "DATA GATHERING: \n",
    "Data gathering involves searching and genrating data across several different \n",
    "sources and file formats and organize the data in your programming environment.\n",
    "Below are the various files gathered from sources for this Project:\n",
    "\n",
    "Twitter_archive_enhanced.csv: \n",
    "This file was downloaded from Udacity's server by manually clicking on the download button.\n",
    "It was upaded to the Jupyter Notebook Workspace and read into a pandas Dataframe.\n",
    "\n",
    "Image_predictions.tsv: \n",
    "This file was downloaded programmatically using the Requests library and the following \n",
    "URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "and was read into the pandas dataframe.\n",
    "\n",
    "Tweet_json.text: \n",
    "This file was meant to be gotten from Twitter API, query the Twitter API for each\n",
    "tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file. \n",
    "However, it was downloaded programmatically using the Requests library and \n",
    "the following URL:https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt\n",
    "from Udacity's server due to issue encountered signung up the twitter account.\n",
    "The tweet_id, retweet_count and the favorite_count were read line by line into a pandas DataFrame.\n",
    "\n",
    "Assessing Data: \n",
    "This involes inspecting the dataset for Data quality issues (i.e. issue with the content) and\n",
    "Lack of tidiness(i.e structural issues). The below issues were detect visually by scrolling through the dataset and \n",
    "programmatically by using code:\n",
    "    \n",
    "Quality issues\n",
    "\n",
    "1..Missing Data (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp)\n",
    "\n",
    "2.p1/p2/p3 columns has incorrect formating (some starts with capital letter while other starts with smaller)\n",
    "\n",
    "3.Inconsistent decimal places or precision values\n",
    "\n",
    "4.Ratings datatype should be float not integer (rating_numerator and rating_denominator)\n",
    "\n",
    "5.Dividing the rating_numerator by rating_denominator to form the rating column\n",
    "\n",
    "6.Inaccurate name column (a, an, all, the, this, by, not, such)\n",
    "\n",
    "7.Erroneous Datatype (timestamp)\n",
    "\n",
    "8.Changing the tweet_id datatype from integer to object since it won't be use for calculations\n",
    "\n",
    "Tidiness issues\n",
    "\n",
    "1.splitted Dog stage into four columns instead one column (doggo, floofer, pupper, puppo).\n",
    "2.Merge the twitter_archive Dataframe with image_pred Dataframe.\n",
    "\n",
    "Cleaning Data:\n",
    "This involes fixing the quality and tidiness issues detected during Data assessment.\n",
    "Below are the steps taken to fix the issues:\n",
    "    \n",
    "Quality issues    \n",
    "\n",
    "1. Dropping the columns in twitter_clean dataframe with missing values as the are no going to be useful\n",
    "2. Converting the p1/p2/p3 to Title case\n",
    "3. Converting the values to 8 decimal places for consistency\n",
    "4. Converting the rating_numerator and rating_denominator to float datatype. \n",
    "5. Dividing the rating_numerator by the rating_denominator and assigning the value to a new column rating\n",
    "6. Dropping words that are not Dog names which are in small letters\n",
    "7. Converting assigned timestamp column from object datatype to datetime datatype.\n",
    "8. Changing the tweet_id datatype from integer to object\n",
    "\n",
    "Tidiness issues\n",
    "1. Combining doggo, floofer, pupper and puppo clumns into one column called dog_stage\n",
    "2. Merging the twitter_archive Dataframe with image_pred Dataframe.\n",
    "\n",
    "The cleaned Dataset was stored in a different file called twitter_archive_master.csv\n",
    "for data analysis and viualizzation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
